# ML-basics
ML basic codes
crash course into ML classificaiton and notion about prediction

# Data Science - DS, Artificial Intelligence - AI, Machine Learning

Data science is the process of extracting knowledge from data. This can be done through a variety of techniques, including data mining, machine learning, and natural language processing.
AI is a process where computers are taught to think for themselves. This can be done through a variety of techniques, including machine learning, deep learning, and natural language processing.
check: https://beta.openai.com/examples/default-factual-answering (for coders e.g. https://beta.openai.com/playground/p/default-fix-python-bugs?model=code-davinci-002 )


# Machine Learning

Machine learning is a process where computers are taught to learn from data, without being explicitly programmed. This is done through a process of iteration, where the computer is given a set of data and then asked to find patterns in that data. It then uses those patterns to make predictions about future data.

# Classification - Decision function

Classification is a process where a computer is taught to identify patterns in data and group them into categories. This can be used, for example, to identify different types of animals by their characteristics.
A decision function is a mathematical function that takes in input data and outputs a decision. This function can be used to determine, for example, whether or not to accept or reject a loan application.
Example : https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html#sphx-glr-auto-examples-classification-plot-classifier-comparison-py

# Classifier comparison

(see. Build_ML_intuition.ipynb above)

A comparison of a several classifiers in scikit-learn on synthetic datasets. The point of this example is to illustrate the nature of decision boundaries of different classifiers. This should be taken with a grain of salt, as the intuition conveyed by these examples does not necessarily carry over to real datasets.

Particularly in high-dimensional spaces, data can more easily be separated linearly and the simplicity of classifiers such as naive Bayes and linear SVMs might lead to better generalization than is achieved by other classifiers.

The plots show training points in solid colors and testing points semi-transparent. The lower right shows the classification accuracy on the test set.
